---
title: "业务并发"
weight: 1
# bookFlatSection: false
# bookToc: true
# bookHidden: false
# bookCollapseSection: false
# bookComments: false
# bookSearchExclude: false
---

在业务中我们经常会对很多个系统进行外部调用，此时各系统独立部署，此时并发访问并不会对被调用系统造成过多压力，并且由于大部分时候操作没有先后顺序，可以支持并发获取相应的数据。

这个时候如果顺序执行的话，最长的执行时间为各个系统的总和，在对RT要求高的场景下无法达到预期，所以需要并发进行处理。

## 一.Go原生解决方案

看到这个场景，我们自然而然会想到 `waitgroup` ，通过并发开始执行，然后 `wait` 等到所有执行完成后再一起返回。

而Go本身也做了一次封装   `errgroup.Group`

能够在执行后获取第一个出现的错误。

我们看下面的代码看如何进行使用：

```go
func main() {
	var eg errgroup.Group

	eg.Go(func() error {
		return errors.New("test1")
	})

	eg.Go(func() error {
		return errors.New("test2")
	})

	if err := eg.Wait(); err != nil {
		fmt.Println(err)
	}
}
```

可以看到用法比较简单，只需要声明一个 [`errgroup.Group`](http://errgroup.Group) 后，通过 `Go` 方法来将执行方法传入即可。

方法的签名也只限定了返回值是 `error` ,其他参数我们可以通过闭包的方式进行传递。

我们来看一下 `Go` 内部是如何实现的：

```go
func (g *Group) Go(f func() error) {
	g.wg.Add(1)

	go func() {
		defer g.wg.Done()

		*// 执行出错时，只保存其中一个错误*
		if err := f(); err != nil {
			*// 通过sync.Once记录下第一个出错的err信息*
			g.errOnce.Do(func() {
				g.err = err
				*// 如果包装了cancel，也就是context的CancelFunc，执行退出操作*
				if g.cancel != nil {
					g.cancel()
				}
			})
		}
	}()
}
```

从代码中没有看到 `recover` 的使用，如果出现 Panic，内部未捕捉，会导致程序崩溃。

并且只通过 `sync.Once` 的方法只能保存到一个错误，无法得到所有执行的错误，并且大部分业务场景下，报错文案有特定的要求，`errGroup` 也无法支持 。

并且如果执行函数需要有**超时控制和并发数控制**，它同样无法支持。

再看一下 `Wait` 的方法：

```go
*// 阻塞所有的通过Go加入的goroutine，然后等待他们一个个执行完成
// 然后返回第一个出错的goroutine的错误信息*
func (g *Group) Wait() error {
	*// 借助于waitgroup实现*
	g.wg.Wait()
	*// 如果包装了cancel，也就是context的CancelFunc，执行退出操作*
	if g.cancel != nil {
		g.cancel()
	}
	return g.err
}
```

`sync.WaitGroup` 的方式来实现等待所有协程执行完成，这部分在我们的实现中仍然会进行保留

## 二.要支持的特性

根据上面所说到的 `errGroup` 无法实现的内容，我们来将其一一补足

1.支持有错误快速失败 ，**产生错误时可以及时停止**，支持多种中断策略。e.g. 发生一个错误立即停止或者前置函数出现错误时立即停止。

2.支持执行时支持增加超时，避免耗时操作

3.操作出现 `panic` 的话能够进行 `recover`

4.并且按传入的顺序将错误进行返回

5.支持并发数控制

### **2.1 错误处理的实现**

首先我们需要将错误按顺序进行保存，所以声明一个slice切片存储错误

```go
type concurrencyGroupErrs struct {
	sync.Mutex *// 扩容时保证并发安全*
	errs       []error
}

func newConcurrencyGroupErrs() *concurrencyGroupErrs {
	return &concurrencyGroupErrs{
		errs: make([]error, 8), *// 默认保存8个错误*
	}
}
```

按照下标设置错误，并且由于设置时无法保证切片容量一定满足，所以当切片长度不满足时需要及时进行扩容

```go
func (cge *concurrencyGroupErrs) growsErrSlice(index int) {
	*// 不需要扩容直接返回*
	if len(cge.errs) > index {
		return}
	cge.Lock()
	defer cge.Unlock()
	*// 二次检查，避免重复扩容*
	if len(cge.errs) > index {
		return
	}

	*// 真正开始执行扩容*
	growLen := 0
	if len(cge.errs) < 1024 {
		*// 小于1024按原长度两倍进行扩容，避免需要频繁进行扩容*
		growLen = len(cge.errs)
	} else {
		*// 大于1024 则按原长度的0.25进行扩容*
		growLen = int(math.Ceil(float64(len(cge.errs)) * 0.25))
	}
	groupErrs := make([]error, growLen)
	cge.errs = append(cge.errs, groupErrs...)
}

func (cge *concurrencyGroupErrs) setErr(err error, index int) {
	cge.growsErrSlice(index)
	cge.errs[index] = err
}
```

通过上述方法我们已经实现了将**错误进行顺序存储并返回（第四点）**

```go
*// GetAllRealErrs
// @Description: 获取执行结果真正的error*
func (cge *concurrencyGroupErrs) GetAllRealErrs() []error {
	errs := make([]error, 0, len(cge.errs))
	for _, err := range cge.errs {
		if err != nil {
			errs = append(errs, err)
		}
	}
	return errs
}

*// GetFirstErr
// @Description: 获取第一个错误*
func (cge *concurrencyGroupErrs) GetFirstErr() error {
	for _, err := range cge.errs {
		if err != nil {
			return err
		}
	}
	return nil
}
```

`concurrencyGroupErrs` 提供获取错误的方法，方便外部进行调用。

测试保证扩容的正确性

```go
func TestErrs(t *testing.T) {
	gErr := newConcurrencyGroupErrs()
	assert.Equal(t, 8, len(gErr.errs))
	for i := 0; i < 8; i++ {
		gErr.setErr(errors.New(fmt.Sprintf("%d", i)), i)
		assert.Equal(t, 8, len(gErr.errs))
	}
	assert.Equal(t, 8, len(gErr.errs))
	assert.Equal(t, len(gErr.errs), cap(gErr.errs))

	for i := 8; i < 1024; i++ {
		gErr.setErr(errors.New(fmt.Sprintf("%d", i)), i)
	}
	assert.Equal(t, 1024, len(gErr.errs))
}
```

### **2.2 并发执行的实现**

首先定义了传入的执行函数信息

```go
type groupGoFunc func(ctx context.Context) errortype groupFuncInfo struct {
	index  int         *// 执行函数的顺序信息*
	f      groupGoFunc *// 真正需要执行的函数*
	cancel func()
}
```

执行的Group结构

```go
*// ConcurrencyGroup
// @Description: 并发执行的group结构体*
type ConcurrencyGroup struct {
	cancel func()

	wg            sync.WaitGroup
	concurrencyCh chan struct{}
	groupFuncs    []*groupFuncInfo

	*concurrencyGroupParam

	*concurrencyGroupErrs
}

func NewConcurrencyGroup(opts ...GroupParamOptFunc) *ConcurrencyGroup {
	cg := &ConcurrencyGroup{
		cancel:               nil,
		wg:                   sync.WaitGroup{},
		groupFuncs:           make([]*groupFuncInfo, 0),
		concurrencyGroupErrs: newConcurrencyGroupErrs(),
		concurrencyGroupParam: &concurrencyGroupParam{
			concurrency: 8, *//默认并发数为8 ，这里是指真正执行操作的并发数*
		},
	}
	for _, opt := range opts {
		opt(cg.concurrencyGroupParam)
	}
	cg.concurrencyCh = make(chan struct{}, cg.concurrency)
	return cg
}

func (cg *ConcurrencyGroup) Go(f groupGoFunc, ctx context.Context) {
	goFunc := cg.addGoFunc(f, ctx)
	go func() {
		*// 最后执行done,避免recover中还有收尾工作没做*
		defer func() {
			*// 执行完成读走缓冲区数据*
			<-cg.concurrencyCh
			cg.wg.Done()
		}()

		defer func() {
			if err := recover(); err != nil {
				goasync.PanicHandler(err, ctx)
			}
		}()
		*// 如果已经达到最大并发数，则进入等待*
		cg.concurrencyCh <- struct{}{}
		*// 开始执行则设置超时*
		ctx, goFunc.cancel = cg.withContextTimeout(ctx)
		errChan := cg.doFunc(goFunc, ctx)
		select {
		case err := <-errChan:
			cg.setErr(err, goFunc.index)
		case <-ctx.Done(): *// context被done则直接返回*
			cg.setErr(ConcurrencyGroupContextDoneErr, goFunc.index)
		}
	}()
}
```

通过 `concurrencyCh` 来对并发数进行控制，如果缓冲区已满，那么暂时不会执行，执行结束后将 `concurrencyCh` 中数据取走，**让后续协程继续执行 （第五点）**

**通过 `recover` 捕获当前错误 （第三点）**

### 2.3 超时控制

通过构造时传入的参数来对 `context` 的超时进行设置。

```go
func (cg *ConcurrencyGroup) withContextTimeout(ctx context.Context) (context.Context, func()) {
	if cg.timeout <= 0 {
		return ctx, nil
	}
	return context.WithTimeout(ctx, cg.timeout)
}
```

如果 `context` 设置了超时时间，则在超时后会进行中断，默认情况下不会有超时（第二点）

```go
*// isInterruptExec
// @Description: 是否中断执行*
func (cg *ConcurrencyGroup) isInterruptExec(funcIndex int) bool {
	switch cg.interruptType {
	case PreExecFail:
		return cg.beforeHasError(funcIndex)
	case FastFail:
		*// 有错误立即中断*
		return cg.hasError()
	case UninterruptedType:
		return falsedefault:
		*// 默认策略是前置有执行失败则中断*
		return cg.beforeHasError(funcIndex)
	}
}
```

### 2.4 出现错误中断

通过错误的下标进行判断，**来支持多种类型的中断（第一点）**，在每次需要执行前先通过 `isInterruptExec` 来决定是否要继续执行

```go
func (cg *ConcurrencyGroup) doFunc(f *groupFuncInfo, ctx context.Context) chan error {
	errChan := make(chan error, 1)
	*// 不执行直接返回*
	if cg.isInterruptExec(f.index) {
		errChan <- ConcurrencyGroupInterruptErr
		return errChan
	}
	go func() {
		defer func() {
			if err := recover(); err != nil {
				goasync.PanicHandler(err, ctx)
				errChan <- fmt.Sprintf("%q", err) *// 这里如果不读取一个错误，外部Channel会被阻塞*
			}
		}()
		*// 二次检查，被调度时产生错误了*
		if cg.isInterruptExec(f.index) {
			errChan <- ConcurrencyGroupInterruptErr
			return}
		*// 读取错误*
		errChan <- f.f(ctx)
	}()
	return errChan
}
```

至此我们实现了最开始说到的五点特性。 通过一张图来总览下整个实现的结构

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/d90f24c1-55f9-41eb-adf6-3bcaba0388c9/01f1ce61-5567-4edb-83c1-a546bf4cbda0/Untitled.png)

## 三.幂等性处理

从上面我们学习了在业务层面如何并发去调用，那如果业务侧操作的时候同时发起相同的操作，即调用了两次接口，服务端应该怎么处理呢？

如果是查询和删除的操作，这两种本身就具备了幂等性 。

比如我两次查询一条数据，并不会改变数据本身的状态，删除一条数据的话因为删了后再次删除，数据已经不存在了，所以也不需要处理幂等性的问题。

需要处理幂等性的是创建和更新的操作。

比如一个订单支付调用了两次接口，如果没有幂等性处理的话，这个订单将会被支付两次的钱，这个时候数据就发生了错误，这个也我们不想发生的。

当重复发起两次请求的时候，我们更期望的是拒绝掉其中的一次请求，那么如何拒绝掉其中一次请求，就是我们接口如何做好幂等性的方法。

### 3.1 分布式锁

以订单这个场景为例，**订单会有一个唯一的标识，如订单号**。这个时候对同个订单发起一起支付请求时，我们通过订单维度进行上一个分布式锁，其中有一个请求就会因为拿不到锁而被拒绝。

所以通过**分布式锁可以首先拒绝掉重复的请求**。

| 请求一 | 请求二 |
| --- | --- |
| 加锁成功 |  |
| 更新订单操作 | 加锁失败 |
| 释放锁 | 返回失败 |

如果两个订单支付请求由于网络的原因，在两个不同的时间到达了会出现什么情况呢？

首先是第一个请求到达后获得锁并操作成功，释放锁。

第二个请求到达后再进行上锁，这个时候因为前面的操作已经将锁释放，所以能够正常上锁，然后进行扣费操作，这个时候又出现了接口不幂等的问题。

| 请求一 | 请求二 |
| --- | --- |
| 加锁成功 |  |
| 更新订单操作 |  |
| 释放锁 |  |
|  | 加锁成功 |
|  | 更新订单操作 |
|  | 释放锁 |

### 3.2 状态机

如果要解决这个问题，我们可以引入状态机，先对订单的状态进行判断，伪代码如下：

```go
type OrderInfo struct {
	// 订单的状态机
	orderStatus uint8
}

func (o *OrderInfo) IsPay() bool {
	// 通过订单的状态来判断是否已支付
	// 这里可以有多个状态，如果订单已经完成也算是支付成功，状态机可以有多种状态
	return true
}

func (o *OrderInfo) Pay() bool {
	// 支付方法，并将状态机进行扭转
	return true
}

func Pay(orderID string) (isPaySuccess bool) {
	orderInfo := GetOrderData(orderID)
	if orderInfo.IsPay() {
		return true
	}
	return orderInfo.Pay()
}
```

这里通过状态机的方式，**先对数据进行查询，然后进行判断后再进行支付**

但是这个方式会存在一个比较大的问题就是如果并发较大的场景下，会产生大量的非必要查询操作。但是如果是用来保证订单数据最终一致性的任务，则这个方法是很实用的，比如一个订单状态已经异常终结了，这个时候我们也不需要进行支付操作，改造后的代码如下

```go
func (o *OrderInfo) IsOrderComplete() bool {
	// 如果订单已经完成，完成的状态可能有多种，比如用户异常终结也算是已经结束
	return true
}

func Pay(orderID string) (err error) {
	orderInfo := GetOrderData(orderID)
	// 订单已经完成则直接进行返回，不需要再进行支付操作
	if orderInfo.IsOrderComplete() {
		return errors.New("order has complete")
	}
	if orderInfo.IsPay() {
		return errors.New("order has payed")
	}
	if orderInfo.Pay() {
		return nil
	}
	return
}
```

因为有状态机的限制，所以订单不同的状态在支付中会返回不同的结果，这也方便外部系统进行判断，也通过状态机的方式实现了订单数据变更的幂等。

### 3.3 数据库唯一索引

我们也可以通过数据库**唯一索引**的方式来直接保证数据的一致性，当插入的时候因为 `唯一id已经冲突，所以插入会失败`，删除的时候通过唯一的id进行删除，这个时候也只能够删除其中一条数据。

那么这个时候又会出现一个 ABA的问题，我们建立了一个订单和商品的关联关系，然后又将其删除，如果创建的请求由于用户快速操作产生了两次，第一次已经进行创建，然后删除请求到达将关系进行删除，第二次创建请求到达后又进行了创建、这个时候就会出现用户删除了后但是并没有删除成功。

这个时候我们就需要将用户对同个订单的多次请求类似 `log` 的方式进行记录，每次操作的时候都会有一个发起的时间戳，**精确到毫秒级别。**然后通过比对订单数据的最后一个操作的时间，来看是否对到达的请求进行丢弃。

| 时间 | 创建订单请求①(10:50:50) | 创建订单请求②(10:50:51) | 删除订单请求(10:50:52) |
| --- | --- | --- | --- |
| 10:50:53 | 创建订单成功 |  |  |
| 10:50:54 |  |  | 删除订单成功 |
| 10:50:55 |  | 创建订单成功 |  |

这个时候也不必担心日志的数据过多，因为这种数据并不需要保存很久，可能**只需要保留一分钟以内的就可以解决我们的ABA问题。**

如果担心对数据库的压力太大，那么可以通过将对应的数据缓存在Redis中，只要比对最新的时间即可。

### 3.4 乐观锁

并发高的场景下面也可以通过乐观锁进行控制，**如通过给订单增加一个version 字段**，每次操作的时候对version进行+1，然后 WHERE 条件为原来的版本号，**如果有其他操作进行修改，那么对应的这次操作就会失效**，这个时候也避免了给单条数据增加悲观锁导致性能下降。

## 四.最后

到这里我们学习了如何从请求方去增加并发度来提升程序的性能，也知道了如何在分布式情况下处理接口的幂等。

但是在实际的情况中远远不止这些情况，《数据密集型应用》应用中给出了很多其他大数据场景下处理的例子，包含了分布式事务、流式数据等处理，这里没有一一展开，如果对数据量和并发量大的应用设计感兴趣，可以进行阅读

这本书非常详细的描述了数据密集型系统的设计，**数据一致性、[分布式数据存储](https://www.zhihu.com/search?q=%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3340371794%7D)数据分区和数据复制的内容有更高维度的解释。**

也举了很多设计的实例，比如为了追求写入性能而这样通过顺序追加，有的为了追求读取性能而在内存中直接存储，最终呈现出来的是各种各样的优势和缺点。在解决幂等性上也可以通过不同的取舍来实现。

感谢你读到这里，如果喜欢云原生、Go、个人成长的内容可以关注我，让我们一起进步。
